{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "import os\n",
    "import collections\n",
    "from moviepy.editor import VideoFileClip\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# calibrate camera\n",
    "class Camera():\n",
    "    def __init__(self, num_xpts, num_ypts, debug_mode=False):\n",
    "        # number of x points in test images\n",
    "        self.num_xpts = num_xpts\n",
    "        # number of y points in test images\n",
    "        self.num_ypts = num_ypts\n",
    "        # Camera matrix\n",
    "        self.mtx = None\n",
    "        # distortion coeff\n",
    "        self.dist = None\n",
    "        # Camera rotation vectors\n",
    "        self.rvecs = None \n",
    "        #Camera translation vectors\n",
    "        self.tvecs = None\n",
    "        # set the default debug mode\n",
    "        self.debug_mode = debug_mode\n",
    "        # source & destination cordinates for perspective transform (found manually)\n",
    "        self.source_cord = np.float32([[608, 445], [669, 441], [1091, 714], [226, 711]])\n",
    "        self.dest_cordinates = np.float32([[200,0], [1080,0], [1080,719], [200,719]])\n",
    "        \n",
    "        \n",
    "        # perspective transform matrix\n",
    "        self.M = cv2.getPerspectiveTransform(self.source_cord, self.dest_cordinates)\n",
    "        # inverse transform\n",
    "        self.Minv = cv2.getPerspectiveTransform(self.dest_cordinates, self.source_cord)\n",
    "        \n",
    "    \n",
    "    def caliberate_camera(self, files):\n",
    "        print(\"Caliberating the Camera ...\")\n",
    "        images = glob.glob(files)\n",
    "        \n",
    "        objpoints = [] # 3D points in real world space\n",
    "        imgpoints = [] # 2D points in image plane\n",
    "        \n",
    "        # object points .. (0,0,0), (1,0,0),...\n",
    "        objp = np.zeros((self.num_xpts*self.num_ypts,3), np.float32)\n",
    "        objp[:,:2] = np.mgrid[0:self.num_xpts,0:self.num_ypts].T.reshape(-1,2)\n",
    "        \n",
    "        # read images and find the chess board corner\n",
    "        for img in images:\n",
    "            # read image\n",
    "            im = cv2.imread(img)\n",
    "            # convert to gray scale\n",
    "            gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "            # Find the chessboard corners\n",
    "            ret, corners = cv2.findChessboardCorners(gray, (self.num_xpts,self.num_ypts), None)\n",
    "            \n",
    "            # If found, add object points, image points\n",
    "            if ret is True:\n",
    "                objpoints.append(objp)\n",
    "                imgpoints.append(corners)\n",
    "                \n",
    "                # draw and display the corners\n",
    "                img = cv2.drawChessboardCorners(im, (self.num_xpts, self.num_ypts), corners, ret)\n",
    "                cv2.imshow(\"image\",img)\n",
    "                cv2.waitKey(0)\n",
    "            else:\n",
    "                print(\"Warning: Could not find correct number of corners for image {}\".format(img))\n",
    "                \n",
    "        img_size = (img.shape[1], img.shape[0])        \n",
    "        # Get camera matrix and distortion coeff\n",
    "        ret, self.mtx, self.dist, self.rvecs, self.tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    def undistort_image(self, img):\n",
    "        dst = cv2.undistort(img, self.mtx, self.dist, None, self.mtx)\n",
    "        return dst\n",
    "    \n",
    "    def set_debug_mode(self, mode):\n",
    "        self.debug_mode = mode\n",
    "    \n",
    "    def threshold_image(self, img):\n",
    "        # note the image should be un-distorted\n",
    "        # first convert the image to HLS color space and choose S channel as it is invariant under different lighting conditions\n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "        s_channel = hls[:,:,2]\n",
    "        if self.debug_mode:\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(s_channel)\n",
    "            plt.title('S channel')\n",
    "            plt.show()\n",
    "        \n",
    "        # convert the RGB image to gray scale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # equalize the grayscale histogram\n",
    "        gray = cv2.equalizeHist(gray)\n",
    "        \n",
    "        # compute Sobel X\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "        abs_sobelx = np.absolute(sobelx)\n",
    "        sobelx_int = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "        \n",
    "        # create a binary image by thresholding the sobelx\n",
    "        thresh_min = 30\n",
    "        thresh_val = 255\n",
    "        # the below function will replace any pixel value greater than thresh_min with thresh_val as pixel value\n",
    "        ret, sobelx_binary_int = cv2.threshold(sobelx_int, thresh_min, thresh_val, cv2.THRESH_BINARY)\n",
    "        sobelx_binary = np.zeros_like(sobelx_binary_int)\n",
    "        sobelx_binary[(sobelx_binary_int==thresh_val)] = 1\n",
    "        \n",
    "        if self.debug_mode:\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(img)\n",
    "            plt.title('Original image')\n",
    "            plt.show()\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(sobelx_binary_int, cmap='gray')\n",
    "            plt.title('SobelXBinary')\n",
    "            plt.show()\n",
    "            \n",
    "        # s-channel thresholding\n",
    "        sch_min_thresh = 175\n",
    "        sch_max_thresh = 255\n",
    "        sch_binary_int = cv2.inRange(s_channel, sch_min_thresh, sch_max_thresh)\n",
    "        sch_binary = np.zeros_like(sch_binary_int)\n",
    "        sch_binary[(sch_binary_int>=sch_min_thresh) & (sch_binary_int<=sch_max_thresh)] = 1\n",
    "        \n",
    "        if self.debug_mode:\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(sch_binary_int, cmap='gray')\n",
    "            plt.title('Sch-Binary')\n",
    "            plt.show()\n",
    "            \n",
    "        # stack the Sch binary image and sobelX binary image along the depth dimension for individual visualization\n",
    "        if self.debug_mode:\n",
    "            color_binary = np.dstack((np.zeros_like(sobelx_binary_int), sobelx_binary_int, sch_binary_int))\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(color_binary, cmap='gray')\n",
    "            plt.title('Sch-color_binary')\n",
    "            plt.show()\n",
    "            \n",
    "        # combine both binary image\n",
    "        combined_binary = np.zeros_like(sobelx_binary)\n",
    "        combined_binary[(sobelx_binary==1) | (sch_binary==1)] = 1\n",
    "        \n",
    "        if self.debug_mode:\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(combined_binary.astype('uint8'), cmap='gray')\n",
    "            plt.title('Combined-binary')\n",
    "            plt.show()\n",
    "        \n",
    "        return combined_binary\n",
    "            \n",
    "    def get_camera_calib(self):\n",
    "        # function is called when we need to save the camera calibration data to the disk\n",
    "        return self.mtx, self.dist\n",
    "    \n",
    "    def set_camera_calib(self, mtx, dist):\n",
    "        self.mtx = mtx\n",
    "        self.dist = dist\n",
    "        \n",
    "    def perspective_transform(self,img):\n",
    "        # Note input should be un-distorted image\n",
    "        img_size = (img.shape[1], img.shape[0])\n",
    "        perspective_img = cv2.warpPerspective(img, self.M, img_size, flags=cv2.INTER_LINEAR)\n",
    "        return perspective_img\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create camera class object\n",
    "camera = Camera(num_xpts=6, num_ypts=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# calibrate camera\n",
    "path = './camera_cal/calibration*.jpg'\n",
    "camera.caliberate_camera(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# check the undistortion on test images\n",
    "images = glob.glob(path)\n",
    "\n",
    "for img in images:\n",
    "    # read image\n",
    "    im = cv2.imread(img)\n",
    "    cv2.imshow(\"before calibration\",im)\n",
    "    # un distort the image\n",
    "    undist = camera.undistort_image(im)\n",
    "    cv2.imshow(\"after calibration\",undist)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "path = './test_images/*.jpg'\n",
    "images = glob.glob(path)\n",
    "#test the image binary thresholding\n",
    "camera.set_debug_mode(mode=True)\n",
    "img = cv2.imread(images[0])\n",
    "# un-distort the image\n",
    "img_undistort = camera.undistort_image(img)\n",
    "binary_img = camera.threshold_image(img_undistort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mtx, dist =camera.get_camera_calib()\n",
    "# save the camera matrix, distortion coeff to the disk\n",
    "pickle_file = 'camera_calib.pickle'\n",
    "if not os.path.isfile(pickle_file):\n",
    "    print('Saving data to pickle file...')\n",
    "    try:\n",
    "        with open('camera_calib.pickle', 'wb') as pfile:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    'camera_mat': mtx,\n",
    "                    'dist_coeff': dist,\n",
    "            \n",
    "                },\n",
    "                pfile, pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print('Unable to save data to', pickle_file, ':', e)\n",
    "        raise\n",
    "\n",
    "print('Data cached in pickle file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the picke file\n",
    "# Reload the data\n",
    "pickle_file = 'camera_calib.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  pickle_data = pickle.load(f)\n",
    "  mtx = pickle_data['camera_mat']\n",
    "  dist = pickle_data['dist_coeff']\n",
    "  del pickle_data  # Free up memory\n",
    "\n",
    "\n",
    "print('Data and modules loaded.')\n",
    "# set the camera matrix and distortion coeff\n",
    "camera.set_camera_calib(mtx,dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from win32api import GetSystemMetrics\n",
    "\n",
    "#the [x, y] for each right-click event will be stored here\n",
    "right_clicks = list()\n",
    "\n",
    "#this function will be called whenever the mouse is right-clicked\n",
    "def mouse_callback(event, x, y, flags, params):\n",
    "\n",
    "    #right-click event value is 2\n",
    "    if event == 2:\n",
    "        global right_clicks\n",
    "\n",
    "        #store the coordinates of the right-click event\n",
    "        right_clicks.append([x, y])\n",
    "\n",
    "        #this just verifies that the mouse data is being collected\n",
    "        #you probably want to remove this later\n",
    "        print(right_clicks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "path = './test_images/*.jpg'\n",
    "images = glob.glob(path)\n",
    "im = cv2.imread(images[0])\n",
    "# undistort the image\n",
    "img_undistort = camera.undistort_image(im)\n",
    "cv2.imshow('image',img_undistort)\n",
    "#set mouse callback function for window\n",
    "cv2.setMouseCallback('image', mouse_callback)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "src_cordinates = np.float32([[608, 445], [669, 441], [1091, 714], [226, 711]])\n",
    "dest_cordinates = np.float32([[200,0],\n",
    "                         [1080,0],\n",
    "                         [1080,719],\n",
    "                         [200,719]])\n",
    "M = cv2.getPerspectiveTransform(src_cordinates, dest_cordinates)\n",
    "img_size = (im.shape[1], im.shape[0])\n",
    "perspective_img = cv2.warpPerspective(img_undistort, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(perspective_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get the perpspective transform on the combined binary image\n",
    "path = './test_images/*.jpg'\n",
    "images = glob.glob(path)\n",
    "im = cv2.imread(images[0])\n",
    "# undistort the image\n",
    "img_undistort = camera.undistort_image(im)\n",
    "# get the binary image\n",
    "img_binary = camera.threshold_image(img_undistort)\n",
    "# perform perspective transform\n",
    "img_persp = camera.perspective_transform(img_binary)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(img_persp,cmap='gray')\n",
    "plt.show()\n",
    "#img_persp\n",
    "#cv2.imshow(\"image\",img_persp)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Lanes():\n",
    "    def __init__(self, debug_mode=False):\n",
    "        self.frame_no = 0\n",
    "        # locations from last frame\n",
    "        self.xleft_prevframe = None\n",
    "        self.xright_prevframe = None\n",
    "        # locations from current frame\n",
    "        self.xleft_currframe = None\n",
    "        self.xright_currframe = None\n",
    "        # selected x pixel for left/right lane\n",
    "        self.leftx = None\n",
    "        self.rightx = None\n",
    "        # set debug mode\n",
    "        self.debug_mode = debug_mode\n",
    "        # line fit coefficients for the current frame\n",
    "        self.fit_avglen = 5 # frame over which fit coeff are averaged\n",
    "        self.left_fit = collections.deque(maxlen = self.fit_avglen)\n",
    "        self.right_fit = collections.deque(maxlen = self.fit_avglen)\n",
    "        # margin for search round the line fit or the peak histogram value for both  x and y direction\n",
    "        self.margin_fullscan = 100 # this is used in full scan\n",
    "        self.margin  = 25 # this is used for continuing search from previous frames\n",
    "        # number of pixels to be detected to re-center the window (used in first frame line detection)\n",
    "        self.minpix = 50\n",
    "        # Choose the number of sliding windows\n",
    "        self.nwindows = 9\n",
    "        # the below variables are used for plotting the lines and search region on the image\n",
    "        self.left_lane_inds = []\n",
    "        self.right_lane_inds = []\n",
    "        # radius of curvature\n",
    "        self.left_curverad = 0\n",
    "        self.right_curverad = 0\n",
    "        self.dist_frm_center = None\n",
    "        # flag to trigger full scan\n",
    "        self.triggerfulscan = 0\n",
    "        # frame count since either no left or no right line detected\n",
    "        self.numframe_no_l_r = None\n",
    "        # threshold in terms of frame before a full scan is launched\n",
    "        self.numframe_thresh = 5\n",
    "        self.prev_result = None\n",
    "        \n",
    "        \n",
    "    def locate_lines(self, binary_warped):\n",
    "        if self.frame_no == 0 or self.triggerfulscan == 1:\n",
    "            if self.triggerfulscan==1:\n",
    "                print(\"...Fullscan triggered....\")\n",
    "                print(\"Frameno:{}\".format(self.frame_no))\n",
    "                self.numframe_no_l_r = 0\n",
    "                self.triggerfulscan = 0\n",
    "                self.left_fit = []\n",
    "                self.right_fit = []\n",
    "                self.left_lane_inds = []\n",
    "                self.right_lane_inds = []\n",
    "                \n",
    "            # input should be undistorted and warped image (bird's eye view)\n",
    "            # Take a histogram of the bottom half of the image\n",
    "            histogram = np.sum(binary_warped[binary_warped.shape[0]/2:,:], axis=0)\n",
    "            # Create an output image to draw on and  visualize the result\n",
    "            # out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "            # Find the peak of the left and right halves of the histogram\n",
    "            # These will be the starting point for the left and right lines\n",
    "            midpoint = np.int(histogram.shape[0]/2)\n",
    "            leftx_base = np.argmax(histogram[:midpoint])\n",
    "            rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "            # Choose the number of sliding windows\n",
    "            nwindows = self.nwindows\n",
    "            # Set height of windows\n",
    "            window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "            # Identify the x and y positions of all nonzero pixels in the image\n",
    "            nonzero = binary_warped.nonzero()\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            nonzerox = np.array(nonzero[1])\n",
    "            # Current positions to be updated for each window\n",
    "            self.xleft_currframe = leftx_base\n",
    "            self.xright_currframe = rightx_base\n",
    "            # Set the width of the windows +/- margin\n",
    "            margin = self.margin_fullscan\n",
    "            # Set minimum number of pixels found to recenter window\n",
    "            minpix = self.minpix\n",
    "            # Create empty lists to receive left and right lane pixel indices\n",
    "            left_lane_inds = []\n",
    "            right_lane_inds = []\n",
    "            # Step through the windows one by one\n",
    "            for window in range(nwindows):\n",
    "                # Identify window boundaries in x and y (and right and left)\n",
    "                win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "                win_y_high = binary_warped.shape[0] - window*window_height\n",
    "                win_xleft_low = self.xleft_currframe - margin\n",
    "                win_xleft_high = self.xleft_currframe + margin\n",
    "                win_xright_low = self.xright_currframe - margin\n",
    "                win_xright_high = self.xright_currframe + margin\n",
    "                # Draw the windows on the visualization image\n",
    "                #cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "                #cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "                # Identify the nonzero pixels in x and y within the window\n",
    "                good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "                good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "                # Append these indices to the lists\n",
    "                left_lane_inds.append(good_left_inds)\n",
    "                right_lane_inds.append(good_right_inds)\n",
    "                # If you found > minpix pixels, recenter next window on their mean position\n",
    "                if len(good_left_inds) > minpix:\n",
    "                    self.xleft_currframe = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "                if len(good_right_inds) > minpix:        \n",
    "                    self.xright_currframe = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "            # Concatenate the arrays of indices\n",
    "            left_lane_inds = np.concatenate(left_lane_inds)\n",
    "            right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "            # Extract left and right line pixel positions\n",
    "            leftx = nonzerox[left_lane_inds]\n",
    "            lefty = nonzeroy[left_lane_inds] \n",
    "            rightx = nonzerox[right_lane_inds]\n",
    "            righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "            # Fit a second order polynomial to each\n",
    "            self.left_fit.append(np.polyfit(lefty, leftx, 2))\n",
    "            self.right_fit.append(np.polyfit(righty, rightx, 2))\n",
    "            \n",
    "                        \n",
    "        else:\n",
    "            # Assume you now have a new warped binary image \n",
    "            # from the next frame of video (also called \"binary_warped\")\n",
    "            # It's now much easier to find line pixels!\n",
    "            nonzero = binary_warped.nonzero()\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            nonzerox = np.array(nonzero[1])\n",
    "            # set the fit parameters based on previous frame\n",
    "            left_fit  = self.left_fit\n",
    "            right_fit = self.right_fit\n",
    "            margin    = self.margin\n",
    "            # take the average\n",
    "            left_fit = np.mean(left_fit, axis=0)\n",
    "            right_fit = np.mean(right_fit, axis=0)\n",
    "            left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "            right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "            # Again, extract left and right line pixel positions\n",
    "            leftx = nonzerox[left_lane_inds]\n",
    "            lefty = nonzeroy[left_lane_inds] \n",
    "            rightx = nonzerox[right_lane_inds]\n",
    "            righty = nonzeroy[right_lane_inds]\n",
    "            \n",
    "            \n",
    "            if  (len(leftx)==0) or (len(rightx)==0):\n",
    "                self.triggerfulscan = 1\n",
    "            elif (np.max(leftx)>=np.min(rightx)):\n",
    "                self.triggerfulscan = 1\n",
    "            else:\n",
    "                #print(\"avg left indx:{}\".format(np.mean(leftx)))    \n",
    "                #print(\"avg right indx:{}\".format(np.mean(rightx)))   \n",
    "                #print(\"diff:{}\".format(np.mean(rightx)-np.mean(leftx)))  \n",
    "                # Fit a second order polynomial to each\n",
    "                left_fit = np.polyfit(lefty, leftx, 2)\n",
    "                right_fit = np.polyfit(righty, rightx, 2)\n",
    "                self.left_fit.append(left_fit)\n",
    "                self.right_fit.append(right_fit)\n",
    "                \n",
    "        \n",
    "        # increment the frame no\n",
    "        self.frame_no += 1\n",
    "                                \n",
    "        return leftx, lefty, rightx, righty\n",
    "    \n",
    "                        \n",
    "        \n",
    "    def plot_lanes(self, img, binary_warped, leftx, lefty, rightx, righty, Minv):\n",
    "        '''\n",
    "        img: un-warped original color image\n",
    "        binary_warped : warped binary thresholded image\n",
    "        nonzeroy : y indices for all non-zero pixels in binary thresholded warped image\n",
    "        nonzerox : x indices for all non-zero pixels in binary thresholded warped image\n",
    "        '''\n",
    "        \n",
    "        if self.triggerfulscan == 1:\n",
    "            return self.prev_result\n",
    "        \n",
    "        ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "        left_fit = np.mean(self.left_fit, axis=0)\n",
    "        right_fit = np.mean(self.right_fit, axis=0)\n",
    "          \n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "                \n",
    "        # Create an image to draw on and an image to show the selection window\n",
    "        warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "        out_img = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "        \n",
    "        \n",
    "                \n",
    "        pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(out_img, np.int_([pts]), (0,255, 0))\n",
    "                \n",
    "        # un-warp into original image space\n",
    "        unwarp_newimg = cv2.warpPerspective(out_img, Minv, (img.shape[1], img.shape[0]))\n",
    "        result = cv2.addWeighted(img, 1, unwarp_newimg, 0.3, 0)\n",
    "        \n",
    "        \n",
    "        # compute ROC on current frame\n",
    "        self.computeROC(binary_warped.shape[0], binary_warped.shape[1])\n",
    "        \n",
    "        # Write the radius of curvature for each lane \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        left_roc = \"Roc: {0:.2f}m\".format(self.left_curverad) \n",
    "        cv2.putText(result, left_roc, (10,650), font, 1, (255,255,255), 2)\n",
    "        right_roc = \"Roc: {0:.2f}m\".format(self.right_curverad) \n",
    "        cv2.putText(result, right_roc, (1020,650), font, 1, (255,255,255), 2)\n",
    "        dist_text = \"Dist from Center: {0:.2f} cms\".format(self.dist_frm_center)\n",
    "        cv2.putText(result, dist_text, (450,50), font, 1, (255,255,255), 2)\n",
    "                \n",
    "        self.prev_result = result\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def computeROC(self, height, width):\n",
    "        '''\n",
    "        This function is to be called from locate_lines\n",
    "        lefty  : y pixels chosen for line fit for left line in current frame\n",
    "        righty : y pixels chosen for line fit for right line in current frame\n",
    "        leftx  : x pixels chosen for line fit for left line in current frame\n",
    "        rightx : x pixels chosen for line fit for right line in current frame\n",
    "        height : height of the image\n",
    "        '''\n",
    "        ploty = np.linspace(0, 719, num=height)# to cover same y-range as image\n",
    "        left_fit = np.mean(self.left_fit, axis=0)\n",
    "        right_fit = np.mean(self.right_fit, axis=0)\n",
    "        # find predictions for left and right x values\n",
    "        leftx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2] \n",
    "        rightx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        \n",
    "        # Define conversions in x and y from pixels space to meters\n",
    "        ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "        xm_per_pix = 3.7/850 # meters per pixel in x dimension\n",
    "        \n",
    "        # Fit new polynomials to x,y in world space\n",
    "        left_fit_cr = np.polyfit(ploty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "        right_fit_cr = np.polyfit(ploty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "        \n",
    "        y_eval = np.max(ploty)\n",
    "        # Calculate the new radii of curvature\n",
    "        left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "        #print(\"max yeval for right:{}\".format(y_eval))\n",
    "        right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "        # Now our radius of curvature is in meters\n",
    "        #print(left_curverad, 'm', right_curverad, 'm')\n",
    "        self.left_curverad = left_curverad\n",
    "        self.right_curverad = right_curverad\n",
    "        # calculate distance from center in real world co-ordinates\n",
    "        img_center = int(width/2)*xm_per_pix\n",
    "        leftcord   = left_fit_cr[0]*(y_eval*ym_per_pix)**2 + left_fit_cr[1]*y_eval*ym_per_pix + left_fit_cr[2]\n",
    "        rightcord  = right_fit_cr[0]*(y_eval*ym_per_pix)**2 + right_fit_cr[1]*y_eval*ym_per_pix + right_fit_cr[2]\n",
    "        self.dist_frm_center = img_center - (rightcord + leftcord)/2\n",
    "               \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# test the lanes detection\n",
    "path = './test_images/*.jpg'\n",
    "images = glob.glob(path)\n",
    "im = cv2.imread(images[0])\n",
    "# undistort the image\n",
    "img_undistort = camera.undistort_image(im)\n",
    "# get the binary image\n",
    "img_binary = camera.threshold_image(img_undistort)\n",
    "# perform perspective transform\n",
    "img_persp = camera.perspective_transform(img_binary)\n",
    "\n",
    "# instantiate object of class Lanes\n",
    "lanes = Lanes()\n",
    "lanes.locate_lines(img_persp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## test scripts\n",
    "test_images = True\n",
    "test_video1 = False\n",
    "test_video2 = False\n",
    "test_video3 = False\n",
    "dump_frames = False\n",
    "def process_image(img):\n",
    "    # undistort the image\n",
    "    img_undistort = camera.undistort_image(img)\n",
    "    # get the binary image\n",
    "    img_binary = camera.threshold_image(img_undistort)\n",
    "    # perform perspective transform\n",
    "    img_persp = camera.perspective_transform(img_binary)\n",
    "    # locate lanes\n",
    "    leftx, lefty, rightx, righty = lanes.locate_lines(img_persp)\n",
    "    # plot the lanes\n",
    "    Minv = camera.Minv\n",
    "    img_with_lanes = lanes.plot_lanes(img_undistort,img_persp,leftx,lefty,rightx,righty,Minv)\n",
    "    # check lanes\n",
    "    #lanes.check_lanes()\n",
    "    \n",
    "    \n",
    "    if dump_frames:\n",
    "        fname1 = './video_frames/'+ \"frameno_\"+ str(lanes.frame_no)+ 'undist'+ '.jpg'\n",
    "        fname2 = './video_frames/'+ \"frameno_\"+ str(lanes.frame_no)+ 'binary'+ '.jpg'\n",
    "        fname3 = './video_frames/'+ \"frameno_\"+ str(lanes.frame_no)+ 'persp'+ '.jpg'\n",
    "        fname4 = './video_frames/'+ \"frameno_\"+ str(lanes.frame_no)+ 'withlanes'+ '.jpg'\n",
    "        cv2.imwrite(fname1, img_undistort)\n",
    "        mpimg.imsave(fname2, img_binary)\n",
    "        mpimg.imsave(fname3, img_persp)\n",
    "        cv2.imwrite(fname4, img_with_lanes)\n",
    "        \n",
    "    return img_with_lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if test_images:\n",
    "    save_images = True # all images will be saved\n",
    "    path = './test_images/*.jpg'\n",
    "    writepath = './output_images/'\n",
    "    images = glob.glob(path)\n",
    "    #images = images[0] # for debug\n",
    "    \n",
    "    # create camera class object\n",
    "    camera = Camera(num_xpts=6, num_ypts=9)\n",
    "    # create lanes class object\n",
    "    lanes  = Lanes()\n",
    "    # Reload the camera matrix and distortion coeff\n",
    "    pickle_file = 'camera_calib.pickle'\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "      pickle_data = pickle.load(f)\n",
    "      mtx = pickle_data['camera_mat']\n",
    "      dist = pickle_data['dist_coeff']\n",
    "      del pickle_data  # Free up memory\n",
    "\n",
    "    print('Data and modules loaded.')\n",
    "    # set the camera matrix and distortion coeff\n",
    "    camera.set_camera_calib(mtx,dist)\n",
    "    \n",
    "    # Setup the plot grid for test images\n",
    "    plt.figure(figsize = (20,20))\n",
    "    gs1 = gridspec.GridSpec(len(images),2)\n",
    "    gs1.update(wspace=0.025, hspace=0.025)\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    for img in images:\n",
    "        test_image = cv2.imread(img)\n",
    "        img_withdetection = process_image(test_image)\n",
    "        if save_images is True:\n",
    "            # save the image\n",
    "            y=img.split('\\\\')\n",
    "            fname = writepath + y[1] \n",
    "            cv2.imwrite(fname,img_withdetection)\n",
    "            \n",
    "        b,g,r = cv2.split(img_withdetection)\n",
    "        img_withdetection = cv2.merge((r,g,b))\n",
    "        ax1 = plt.subplot(gs1[i])\n",
    "        plt.axis('off')\n",
    "        b,g,r = cv2.split(test_image)\n",
    "        test_image = cv2.merge((r,g,b))\n",
    "        ax1.imshow(test_image)\n",
    "        ax2 = plt.subplot(gs1[i+1])\n",
    "        plt.axis('off')\n",
    "        ax2.imshow(img_withdetection)\n",
    "        i+=2\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on test video1...\n",
      "Data and modules loaded.\n",
      "[MoviePy] >>>> Building video ./project_video_processed_111.mp4\n",
      "[MoviePy] Writing video ./project_video_processed_111.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████▉| 1260/1261 [03:24<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./project_video_processed_111.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_images = False\n",
    "test_video1 = True\n",
    "test_video2 = False\n",
    "test_video3 = False\n",
    "dump_frames = False\n",
    "if test_video1:\n",
    "    print(\"Running on test video1...\")\n",
    "    writepath = './output_images/'\n",
    "    \n",
    "    # create camera class object\n",
    "    camera = Camera(num_xpts=6, num_ypts=9)\n",
    "    # create lanes class object\n",
    "    lanes  = Lanes()\n",
    "    # Reload the camera matrix and distortion coeff\n",
    "    pickle_file = 'camera_calib.pickle'\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "      pickle_data = pickle.load(f)\n",
    "      mtx = pickle_data['camera_mat']\n",
    "      dist = pickle_data['dist_coeff']\n",
    "      del pickle_data  # Free up memory\n",
    "\n",
    "    print('Data and modules loaded.')\n",
    "    # set the camera matrix and distortion coeff\n",
    "    camera.set_camera_calib(mtx,dist)\n",
    "    \n",
    "    #####################################\n",
    "    # Run our pipeline on the test video \n",
    "    #####################################\n",
    "    clip = VideoFileClip(\"./project_video.mp4\")\n",
    "    output_video = \"./project_video_processed_111.mp4\"\n",
    "    output_clip = clip.fl_image(process_image)\n",
    "    output_clip.write_videofile(output_video, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on test video2...\n",
      "Data and modules loaded.\n",
      "[MoviePy] >>>> Building video ./project_video_processed_223.mp4\n",
      "[MoviePy] Writing video ./project_video_processed_223.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                         | 4/485 [00:00<01:11,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█                                        | 13/485 [00:01<01:03,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                       | 24/485 [00:03<00:56,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███▋                                     | 43/485 [00:06<00:54,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███▉                                     | 46/485 [00:06<01:06,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████▌                                    | 54/485 [00:07<01:06,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████▋                                    | 56/485 [00:08<01:18,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████▉                                    | 58/485 [00:08<01:24,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████                                    | 60/485 [00:09<01:26,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▏                                   | 62/485 [00:09<01:25,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▍                                   | 64/485 [00:09<01:25,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▌                                   | 66/485 [00:10<01:27,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▋                                   | 68/485 [00:10<01:29,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▉                                   | 70/485 [00:11<01:30,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████                                   | 72/485 [00:11<01:37,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████▎                                  | 74/485 [00:12<01:28,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▍                                  | 76/485 [00:12<01:37,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▌                                  | 78/485 [00:13<01:34,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▊                                  | 80/485 [00:13<01:27,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████▉                                  | 82/485 [00:14<01:31,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████                                  | 84/485 [00:14<01:34,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████▊                                 | 93/485 [00:16<01:10,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▎                                | 98/485 [00:17<01:10,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▉                               | 108/485 [00:19<00:57,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████▎                              | 113/485 [00:19<01:01,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████▍                              | 115/485 [00:20<01:05,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████▎                             | 125/485 [00:21<00:52,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████▋                            | 141/485 [00:24<00:47,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████▊                            | 143/485 [00:24<00:51,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████▉                            | 145/485 [00:24<00:51,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████                            | 147/485 [00:25<00:55,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████▊                           | 156/485 [00:26<00:57,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████                | 292/485 [00:46<00:27,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|████████████████████████▌               | 298/485 [00:47<00:25,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████████▉               | 303/485 [00:48<00:25,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|█████████████████████████▋              | 312/485 [00:49<00:25,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████▍             | 320/485 [00:50<00:22,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████▊            | 337/485 [00:53<00:19,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████▉            | 339/485 [00:53<00:22,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████            | 341/485 [00:53<00:22,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|█████████████████████████████▏          | 354/485 [00:55<00:17,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████         | 377/485 [00:59<00:14,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████▌        | 383/485 [01:00<00:14,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████▏       | 390/485 [01:01<00:13,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████████████████████████████▎       | 392/485 [01:01<00:14,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████████████████████████████▊       | 398/485 [01:02<00:12,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████████████████████████████▉       | 400/485 [01:02<00:12,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████▏      | 402/485 [01:02<00:12,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████▎      | 404/485 [01:03<00:12,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|█████████████████████████████████▍      | 406/485 [01:03<00:12,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|█████████████████████████████████▋      | 408/485 [01:03<00:12,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|█████████████████████████████████▊      | 410/485 [01:04<00:12,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|█████████████████████████████████▉      | 412/485 [01:04<00:12,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|██████████████████████████████████▏     | 414/485 [01:04<00:11,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|██████████████████████████████████▎     | 416/485 [01:05<00:11,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|██████████████████████████████████▍     | 418/485 [01:05<00:11,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|██████████████████████████████████▋     | 420/485 [01:06<00:11,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|██████████████████████████████████▊     | 422/485 [01:06<00:10,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|██████████████████████████████████▉     | 424/485 [01:06<00:09,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████▏    | 426/485 [01:07<00:09,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|████████████████████████████████████▌   | 443/485 [01:09<00:05,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████▊  | 459/485 [01:11<00:03,  7.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████▌ | 467/485 [01:13<00:02,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|██████████████████████████████████████▊ | 470/485 [01:13<00:02,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|██████████████████████████████████████▉ | 472/485 [01:13<00:01,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|███████████████████████████████████████▎| 477/485 [01:14<00:01,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████▊| 483/485 [01:15<00:00,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 485/485 [01:15<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./project_video_processed_223.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_images = False\n",
    "test_video1 = False\n",
    "test_video2 = True\n",
    "test_video3 = False\n",
    "dump_frames = False\n",
    "if test_video2:\n",
    "    print(\"Running on test video2...\")\n",
    "    writepath = './output_images/'\n",
    "    \n",
    "    # create camera class object\n",
    "    camera = Camera(num_xpts=6, num_ypts=9)\n",
    "    # create lanes class object\n",
    "    lanes  = Lanes()\n",
    "    # Reload the camera matrix and distortion coeff\n",
    "    pickle_file = 'camera_calib.pickle'\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "      pickle_data = pickle.load(f)\n",
    "      mtx = pickle_data['camera_mat']\n",
    "      dist = pickle_data['dist_coeff']\n",
    "      del pickle_data  # Free up memory\n",
    "\n",
    "    print('Data and modules loaded.')\n",
    "    # set the camera matrix and distortion coeff\n",
    "    camera.set_camera_calib(mtx,dist)\n",
    "    \n",
    "    #####################################\n",
    "    # Run our pipeline on the test video \n",
    "    #####################################\n",
    "    clip = VideoFileClip(\"./challenge_video.mp4\")\n",
    "    output_video = \"./project_video_processed_223.mp4\"\n",
    "    output_clip = clip.fl_image(process_image)\n",
    "    output_clip.write_videofile(output_video, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_images = False\n",
    "test_video1 = False\n",
    "test_video2 = False\n",
    "test_video3 = True\n",
    "dump_frames = False\n",
    "if test_video3:\n",
    "    print(\"Running on test video3...\")\n",
    "    writepath = './output_images/'\n",
    "    \n",
    "    # create camera class object\n",
    "    camera = Camera(num_xpts=6, num_ypts=9)\n",
    "    # create lanes class object\n",
    "    lanes  = Lanes()\n",
    "    # Reload the camera matrix and distortion coeff\n",
    "    pickle_file = 'camera_calib.pickle'\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "      pickle_data = pickle.load(f)\n",
    "      mtx = pickle_data['camera_mat']\n",
    "      dist = pickle_data['dist_coeff']\n",
    "      del pickle_data  # Free up memory\n",
    "\n",
    "    print('Data and modules loaded.')\n",
    "    # set the camera matrix and distortion coeff\n",
    "    camera.set_camera_calib(mtx,dist)\n",
    "    \n",
    "    #####################################\n",
    "    # Run our pipeline on the test video \n",
    "    #####################################\n",
    "    clip = VideoFileClip(\"./harder_challenge_video.mp4\")\n",
    "    output_video = \"./project_video_processed_333.mp4\"\n",
    "    output_clip = clip.fl_image(process_image)\n",
    "    output_clip.write_videofile(output_video, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# overlaying the src pts on the test image and showing the warped image (required for project submission)\n",
    "\n",
    "# create camera class object\n",
    "camera = Camera(num_xpts=6, num_ypts=9)\n",
    "# create lanes class object\n",
    "lanes  = Lanes()\n",
    "# Reload the camera matrix and distortion coeff\n",
    "pickle_file = 'camera_calib.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  pickle_data = pickle.load(f)\n",
    "  mtx = pickle_data['camera_mat']\n",
    "  dist = pickle_data['dist_coeff']\n",
    "  del pickle_data  # Free up memory\n",
    "\n",
    "print('Data and modules loaded.')\n",
    "# set the camera matrix and distortion coeff\n",
    "camera.set_camera_calib(mtx,dist)\n",
    "src_cord = camera.source_cord\n",
    "path = './test_images/*.jpg'\n",
    "images = glob.glob(path)\n",
    "im = cv2.imread(images[0])\n",
    "b,g,r = cv2.split(im)\n",
    "im = cv2.merge((r,g,b))\n",
    "# undistort the image\n",
    "img_undistort = camera.undistort_image(im)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(img_undistort)\n",
    "plt.show()\n",
    "# create a blank image\n",
    "out_img = img_undistort*255\n",
    "out_img.shape\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(out_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = [1,2,3,4]\n",
    "print(a)\n",
    "print(a[0:len(a)-1],  a[1:len(a)])\n",
    "print(len(a[1:len(a)]))\n",
    "b = a[1:len(a)]\n",
    "a[0:len(a)-1] = a[1:len(a)]\n",
    "a[3] = 100\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Debug line fit on a image of a frame\n",
    "# create camera class object\n",
    "camera = Camera(num_xpts=6, num_ypts=9)\n",
    "# create lanes class object\n",
    "lanes  = Lanes()\n",
    "# Reload the camera matrix and distortion coeff\n",
    "pickle_file = 'camera_calib.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  pickle_data = pickle.load(f)\n",
    "  mtx = pickle_data['camera_mat']\n",
    "  dist = pickle_data['dist_coeff']\n",
    "  del pickle_data  # Free up memory\n",
    "\n",
    "print('Data and modules loaded.')\n",
    "# set the camera matrix and distortion coeff\n",
    "camera.set_camera_calib(mtx,dist)\n",
    "\n",
    "# the debug image\n",
    "img = './debug/frameno_623undist.jpg'\n",
    "\n",
    "img_undistort = cv2.imread(img)\n",
    "plt.figure()\n",
    "plt.imshow(img_undistort)\n",
    "plt.show()\n",
    "\n",
    "# get the binary image\n",
    "img_binary = camera.threshold_image(img_undistort)\n",
    "plt.figure()\n",
    "plt.imshow(img_binary)\n",
    "plt.show()\n",
    "# perform perspective transform\n",
    "img_persp = camera.perspective_transform(img_binary)\n",
    "plt.figure()\n",
    "plt.imshow(img_persp)\n",
    "plt.show()\n",
    "# locate lanes\n",
    "leftx, lefty, rightx, righty = lanes.locate_lines(img_persp)\n",
    "# plot the lanes\n",
    "Minv = camera.Minv\n",
    "img_with_lanes = lanes.plot_lanes(img_undistort,img_persp,leftx,lefty,rightx,righty,Minv)\n",
    "plt.figure()\n",
    "plt.imshow(img_with_lanes)\n",
    "plt.show()\n",
    "cv2.imwrite('./Debug/op_img.jpg',img_with_lanes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
