{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# calibrate camera\n",
    "class Camera():\n",
    "    def __init__(self, num_xpts, num_ypts, debug_mode=False):\n",
    "        # number of x points in test images\n",
    "        self.num_xpts = num_xpts\n",
    "        # number of y points in test images\n",
    "        self.num_ypts = num_ypts\n",
    "        # Camera matrix\n",
    "        self.mtx = None\n",
    "        # distortion coeff\n",
    "        self.dist = None\n",
    "        # Camera rotation vectors\n",
    "        self.rvecs = None \n",
    "        #Camera translation vectors\n",
    "        self.tvecs = None\n",
    "        # set the default debug mode\n",
    "        self.debug_mode = debug_mode\n",
    "        # source & destination cordinates for perspective transform (found manually)\n",
    "        self.source_cord = np.float32([[608, 445], [669, 441], [1091, 714], [226, 711]])\n",
    "        self.dest_cordinates = np.float32([[200,0], [1080,0], [1080,719], [200,719]])\n",
    "        \n",
    "        \n",
    "        # perspective transform matrix\n",
    "        self.M = cv2.getPerspectiveTransform(self.source_cord, self.dest_cordinates)\n",
    "        # inverse transform\n",
    "        self.Minv = cv2.getPerspectiveTransform(self.dest_cordinates, self.source_cord)\n",
    "        \n",
    "    \n",
    "    def caliberate_camera(self, files):\n",
    "        print(\"Caliberating the Camera ...\")\n",
    "        images = glob.glob(files)\n",
    "        \n",
    "        objpoints = [] # 3D points in real world space\n",
    "        imgpoints = [] # 2D points in image plane\n",
    "        \n",
    "        # object points .. (0,0,0), (1,0,0),...\n",
    "        objp = np.zeros((self.num_xpts*self.num_ypts,3), np.float32)\n",
    "        objp[:,:2] = np.mgrid[0:self.num_xpts,0:self.num_ypts].T.reshape(-1,2)\n",
    "        \n",
    "        # read images and find the chess board corner\n",
    "        for img in images:\n",
    "            # read image\n",
    "            im = cv2.imread(img)\n",
    "            # convert to gray scale\n",
    "            gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "            # Find the chessboard corners\n",
    "            ret, corners = cv2.findChessboardCorners(gray, (self.num_xpts,self.num_ypts), None)\n",
    "            \n",
    "            # If found, add object points, image points\n",
    "            if ret is True:\n",
    "                objpoints.append(objp)\n",
    "                imgpoints.append(corners)\n",
    "                \n",
    "                # draw and display the corners\n",
    "                img = cv2.drawChessboardCorners(im, (self.num_xpts, self.num_ypts), corners, ret)\n",
    "                cv2.imshow(\"image\",img)\n",
    "                cv2.waitKey(0)\n",
    "            else:\n",
    "                print(\"Warning: Could not find correct number of corners for image {}\".format(img))\n",
    "                \n",
    "        img_size = (img.shape[1], img.shape[0])        \n",
    "        # Get camera matrix and distortion coeff\n",
    "        ret, self.mtx, self.dist, self.rvecs, self.tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    def undistort_image(self, img):\n",
    "        dst = cv2.undistort(img, self.mtx, self.dist, None, self.mtx)\n",
    "        return dst\n",
    "    \n",
    "    def set_debug_mode(self, mode):\n",
    "        self.debug_mode = mode\n",
    "    \n",
    "    def threshold_image(self, img):\n",
    "        # note the image should be un-distorted\n",
    "        # first convert the image to HLS color space and choose S channel as it is invariant under different lighting conditions\n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "        s_channel = hls[:,:,2]\n",
    "        if self.debug_mode:\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(s_channel)\n",
    "            plt.title('S channel')\n",
    "            plt.show()\n",
    "        \n",
    "        # convert the RGB image to gray scale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # equalize the grayscale histogram\n",
    "        gray = cv2.equalizeHist(gray)\n",
    "        \n",
    "        # compute Sobel X\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "        abs_sobelx = np.absolute(sobelx)\n",
    "        sobelx_int = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "        \n",
    "        # create a binary image by thresholding the sobelx\n",
    "        thresh_min = 30\n",
    "        thresh_val = 255\n",
    "        # the below function will replace any pixel value greater than thresh_min with thresh_val as pixel value\n",
    "        ret, sobelx_binary_int = cv2.threshold(sobelx_int, thresh_min, thresh_val, cv2.THRESH_BINARY)\n",
    "        sobelx_binary = np.zeros_like(sobelx_binary_int)\n",
    "        sobelx_binary[(sobelx_binary_int==thresh_val)] = 1\n",
    "        \n",
    "        if self.debug_mode:\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(img)\n",
    "            plt.title('Original image')\n",
    "            plt.show()\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(sobelx_binary_int, cmap='gray')\n",
    "            plt.title('SobelXBinary')\n",
    "            plt.show()\n",
    "            \n",
    "        # s-channel thresholding\n",
    "        sch_min_thresh = 175\n",
    "        sch_max_thresh = 255\n",
    "        sch_binary_int = cv2.inRange(s_channel, sch_min_thresh, sch_max_thresh)\n",
    "        sch_binary = np.zeros_like(sch_binary_int)\n",
    "        sch_binary[(sch_binary_int>=sch_min_thresh) & (sch_binary_int<=sch_max_thresh)] = 1\n",
    "        \n",
    "        if self.debug_mode:\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(sch_binary_int, cmap='gray')\n",
    "            plt.title('Sch-Binary')\n",
    "            plt.show()\n",
    "            \n",
    "        # stack the Sch binary image and sobelX binary image along the depth dimension for individual visualization\n",
    "        if self.debug_mode:\n",
    "            color_binary = np.dstack((np.zeros_like(sobelx_binary_int), sobelx_binary_int, sch_binary_int))\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(color_binary, cmap='gray')\n",
    "            plt.title('Sch-color_binary')\n",
    "            plt.show()\n",
    "            \n",
    "        # combine both binary image\n",
    "        combined_binary = np.zeros_like(sobelx_binary)\n",
    "        combined_binary[(sobelx_binary==1) | (sch_binary==1)] = 1\n",
    "        \n",
    "        if self.debug_mode:\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(combined_binary.astype('uint8'), cmap='gray')\n",
    "            plt.title('Combined-binary')\n",
    "            plt.show()\n",
    "        \n",
    "        return combined_binary\n",
    "            \n",
    "    def get_camera_calib(self):\n",
    "        # function is called when we need to save the camera calibration data to the disk\n",
    "        return self.mtx, self.dist\n",
    "    \n",
    "    def set_camera_calib(self, mtx, dist):\n",
    "        self.mtx = mtx\n",
    "        self.dist = dist\n",
    "        \n",
    "    def perspective_transform(self,img):\n",
    "        # Note input should be un-distorted image\n",
    "        img_size = (img.shape[1], img.shape[0])\n",
    "        perspective_img = cv2.warpPerspective(img, self.M, img_size, flags=cv2.INTER_LINEAR)\n",
    "        return perspective_img\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create camera class object\n",
    "camera = Camera(num_xpts=6, num_ypts=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# calibrate camera\n",
    "path = './camera_cal/calibration*.jpg'\n",
    "camera.caliberate_camera(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# check the undistortion on test images\n",
    "images = glob.glob(path)\n",
    "\n",
    "for img in images:\n",
    "    # read image\n",
    "    im = cv2.imread(img)\n",
    "    cv2.imshow(\"before calibration\",im)\n",
    "    # un distort the image\n",
    "    undist = camera.undistort_image(im)\n",
    "    cv2.imshow(\"after calibration\",undist)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "path = './test_images/*.jpg'\n",
    "images = glob.glob(path)\n",
    "#test the image binary thresholding\n",
    "camera.set_debug_mode(mode=True)\n",
    "img = cv2.imread(images[0])\n",
    "# un-distort the image\n",
    "img_undistort = camera.undistort_image(img)\n",
    "binary_img = camera.threshold_image(img_undistort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mtx, dist =camera.get_camera_calib()\n",
    "# save the camera matrix, distortion coeff to the disk\n",
    "pickle_file = 'camera_calib.pickle'\n",
    "if not os.path.isfile(pickle_file):\n",
    "    print('Saving data to pickle file...')\n",
    "    try:\n",
    "        with open('camera_calib.pickle', 'wb') as pfile:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    'camera_mat': mtx,\n",
    "                    'dist_coeff': dist,\n",
    "            \n",
    "                },\n",
    "                pfile, pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print('Unable to save data to', pickle_file, ':', e)\n",
    "        raise\n",
    "\n",
    "print('Data cached in pickle file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the picke file\n",
    "# Reload the data\n",
    "pickle_file = 'camera_calib.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  pickle_data = pickle.load(f)\n",
    "  mtx = pickle_data['camera_mat']\n",
    "  dist = pickle_data['dist_coeff']\n",
    "  del pickle_data  # Free up memory\n",
    "\n",
    "\n",
    "print('Data and modules loaded.')\n",
    "# set the camera matrix and distortion coeff\n",
    "camera.set_camera_calib(mtx,dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from win32api import GetSystemMetrics\n",
    "\n",
    "#the [x, y] for each right-click event will be stored here\n",
    "right_clicks = list()\n",
    "\n",
    "#this function will be called whenever the mouse is right-clicked\n",
    "def mouse_callback(event, x, y, flags, params):\n",
    "\n",
    "    #right-click event value is 2\n",
    "    if event == 2:\n",
    "        global right_clicks\n",
    "\n",
    "        #store the coordinates of the right-click event\n",
    "        right_clicks.append([x, y])\n",
    "\n",
    "        #this just verifies that the mouse data is being collected\n",
    "        #you probably want to remove this later\n",
    "        print(right_clicks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "path = './test_images/*.jpg'\n",
    "images = glob.glob(path)\n",
    "im = cv2.imread(images[0])\n",
    "# undistort the image\n",
    "img_undistort = camera.undistort_image(im)\n",
    "cv2.imshow('image',img_undistort)\n",
    "#set mouse callback function for window\n",
    "cv2.setMouseCallback('image', mouse_callback)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "src_cordinates = np.float32([[608, 445], [669, 441], [1091, 714], [226, 711]])\n",
    "dest_cordinates = np.float32([[200,0],\n",
    "                         [1080,0],\n",
    "                         [1080,719],\n",
    "                         [200,719]])\n",
    "M = cv2.getPerspectiveTransform(src_cordinates, dest_cordinates)\n",
    "img_size = (im.shape[1], im.shape[0])\n",
    "perspective_img = cv2.warpPerspective(img_undistort, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(perspective_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get the perpspective transform on the combined binary image\n",
    "path = './test_images/*.jpg'\n",
    "images = glob.glob(path)\n",
    "im = cv2.imread(images[0])\n",
    "# undistort the image\n",
    "img_undistort = camera.undistort_image(im)\n",
    "# get the binary image\n",
    "img_binary = camera.threshold_image(img_undistort)\n",
    "# perform perspective transform\n",
    "img_persp = camera.perspective_transform(img_binary)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(img_persp,cmap='gray')\n",
    "plt.show()\n",
    "#img_persp\n",
    "#cv2.imshow(\"image\",img_persp)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Lanes():\n",
    "    def __init__(self, debug_mode=False):\n",
    "        self.frame_no = 0\n",
    "        # locations from last frame\n",
    "        self.xleft_prevframe = None\n",
    "        self.xright_prevframe = None\n",
    "        # locations from current frame\n",
    "        self.xleft_currframe = None\n",
    "        self.xright_currframe = None\n",
    "        # selected x pixel for left/right lane\n",
    "        self.leftx = None\n",
    "        self.rightx = None\n",
    "        # set debug mode\n",
    "        self.debug_mode = debug_mode\n",
    "        # line fit coefficients for the current frame\n",
    "        self.left_fit = []\n",
    "        self.right_fit = []\n",
    "        self.fit_avglen = 5 # frame over which fit coeff are averaged\n",
    "        # margin for search round the line fit or the peak histogram value for both  x and y direction\n",
    "        self.margin = 100\n",
    "        # number of pixels to be detected to re-center the window (used in first frame line detection)\n",
    "        self.minpix = 50\n",
    "        # Choose the number of sliding windows\n",
    "        self.nwindows = 9\n",
    "        # the below variables are used for plotting the lines and search region on the image\n",
    "        self.left_lane_inds = []\n",
    "        self.right_lane_inds = []\n",
    "        # radius of curvature\n",
    "        self.left_curverad = 0\n",
    "        self.right_curverad = 0\n",
    "        self.dist_frm_center = None\n",
    "        # flag to trigger full scan\n",
    "        self.triggerfulscan = 0\n",
    "        # frame count since either no left or no right line detected\n",
    "        self.numframe_no_l_r = None\n",
    "        # threshold in terms of frame before a full scan is launched\n",
    "        self.numframe_thresh = 5\n",
    "        self.prev_result = None\n",
    "        \n",
    "        \n",
    "    def locate_lines(self, binary_warped):\n",
    "        if self.frame_no == 0 or self.triggerfulscan == 1:\n",
    "            if self.triggerfulscan==1:\n",
    "                print(\"...Fullscan triggered....\")\n",
    "                print(\"Frameno:{}\".format(self.frame_no))\n",
    "                self.numframe_no_l_r = 0\n",
    "                self.triggerfulscan = 0\n",
    "                self.left_fit = []\n",
    "                self.left_fit = []\n",
    "            # input should be undistorted and warped image (bird's eye view)\n",
    "            # Take a histogram of the bottom half of the image\n",
    "            histogram = np.sum(binary_warped[binary_warped.shape[0]/2:,:], axis=0)\n",
    "            # Create an output image to draw on and  visualize the result\n",
    "            # out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "            # Find the peak of the left and right halves of the histogram\n",
    "            # These will be the starting point for the left and right lines\n",
    "            midpoint = np.int(histogram.shape[0]/2)\n",
    "            leftx_base = np.argmax(histogram[:midpoint])\n",
    "            rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "            # Choose the number of sliding windows\n",
    "            nwindows = self.nwindows\n",
    "            # Set height of windows\n",
    "            window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "            # Identify the x and y positions of all nonzero pixels in the image\n",
    "            nonzero = binary_warped.nonzero()\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            nonzerox = np.array(nonzero[1])\n",
    "            # Current positions to be updated for each window\n",
    "            self.xleft_currframe = leftx_base\n",
    "            self.xright_currframe = rightx_base\n",
    "            # Set the width of the windows +/- margin\n",
    "            margin = self.margin\n",
    "            # Set minimum number of pixels found to recenter window\n",
    "            minpix = self.minpix\n",
    "            # Create empty lists to receive left and right lane pixel indices\n",
    "            left_lane_inds = []\n",
    "            right_lane_inds = []\n",
    "            # Step through the windows one by one\n",
    "            for window in range(nwindows):\n",
    "                # Identify window boundaries in x and y (and right and left)\n",
    "                win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "                win_y_high = binary_warped.shape[0] - window*window_height\n",
    "                win_xleft_low = self.xleft_currframe - margin\n",
    "                win_xleft_high = self.xleft_currframe + margin\n",
    "                win_xright_low = self.xright_currframe - margin\n",
    "                win_xright_high = self.xright_currframe + margin\n",
    "                # Draw the windows on the visualization image\n",
    "                #cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "                #cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "                # Identify the nonzero pixels in x and y within the window\n",
    "                good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "                good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "                # Append these indices to the lists\n",
    "                left_lane_inds.append(good_left_inds)\n",
    "                right_lane_inds.append(good_right_inds)\n",
    "                # If you found > minpix pixels, recenter next window on their mean position\n",
    "                if len(good_left_inds) > minpix:\n",
    "                    self.xleft_currframe = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "                if len(good_right_inds) > minpix:        \n",
    "                    self.xright_currframe = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "            # Concatenate the arrays of indices\n",
    "            left_lane_inds = np.concatenate(left_lane_inds)\n",
    "            right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "            # Extract left and right line pixel positions\n",
    "            leftx = nonzerox[left_lane_inds]\n",
    "            lefty = nonzeroy[left_lane_inds] \n",
    "            rightx = nonzerox[right_lane_inds]\n",
    "            righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "            # Fit a second order polynomial to each\n",
    "            self.left_fit.append(np.polyfit(lefty, leftx, 2))\n",
    "            self.right_fit.append(np.polyfit(righty, rightx, 2))\n",
    "            \n",
    "                        \n",
    "        else:\n",
    "            # Assume you now have a new warped binary image \n",
    "            # from the next frame of video (also called \"binary_warped\")\n",
    "            # It's now much easier to find line pixels!\n",
    "            nonzero = binary_warped.nonzero()\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            nonzerox = np.array(nonzero[1])\n",
    "            # set the fit parameters based on previous frame\n",
    "            left_fit  = self.left_fit\n",
    "            right_fit = self.right_fit\n",
    "            margin    = self.margin\n",
    "            # take the average\n",
    "            left_fit = np.mean(left_fit, axis=0)\n",
    "            right_fit = np.mean(right_fit, axis=0)\n",
    "            left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "            right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "            # Again, extract left and right line pixel positions\n",
    "            leftx = nonzerox[left_lane_inds]\n",
    "            lefty = nonzeroy[left_lane_inds] \n",
    "            rightx = nonzerox[right_lane_inds]\n",
    "            righty = nonzeroy[right_lane_inds]\n",
    "            \n",
    "            \n",
    "            if  (len(leftx)==0) or (len(rightx)==0):\n",
    "                self.triggerfulscan = 1\n",
    "            elif (np.max(leftx)>=np.min(rightx)):\n",
    "                self.triggerfulscan = 1\n",
    "            else:\n",
    "                # Fit a second order polynomial to each\n",
    "                left_fit = np.polyfit(lefty, leftx, 2)\n",
    "                right_fit = np.polyfit(righty, rightx, 2)\n",
    "                \n",
    "                if len(self.left_fit)<self.fit_avglen:\n",
    "                    self.left_fit.append(left_fit)\n",
    "                else:\n",
    "                    self.left_fit[0:self.fit_avglen-1] = self.left_fit[1:self.fit_avglen]\n",
    "                    self.left_fit.append(left_fit)\n",
    "\n",
    "                if len(self.right_fit)<self.fit_avglen:\n",
    "                    self.right_fit.append(right_fit)\n",
    "                else:\n",
    "                    self.right_fit[0:self.fit_avglen-1] = self.right_fit[1:self.fit_avglen]\n",
    "                    self.right_fit.append(right_fit)\n",
    "                    # update the chosen left and right lane indices (used for plotting) for the current frame\n",
    "                    self.left_lane_inds = left_lane_inds\n",
    "                    self.right_lane_inds = right_lane_inds\n",
    "                    \n",
    "                \n",
    "            # Fit a second order polynomial to each\n",
    "            #left_fit = np.polyfit(lefty, leftx, 2)\n",
    "            #right_fit = np.polyfit(righty, rightx, 2)\n",
    "            # set the line fit cordinates for the current frame\n",
    "            \n",
    "            #if len(self.left_fit)<5:\n",
    "            #    self.left_fit.append(left_fit)\n",
    "            #else:\n",
    "            #    self.left_fit[0:4] = self.left_fit[1:5]\n",
    "            #    self.left_fit.append(left_fit)\n",
    "                \n",
    "            #if len(self.right_fit)<5:\n",
    "            #    self.right_fit.append(right_fit)\n",
    "            #else:\n",
    "            #    self.right_fit[0:4] = self.right_fit[1:5]\n",
    "            #    self.right_fit.append(right_fit)\n",
    "        \n",
    "        # increment the frame no\n",
    "        self.frame_no += 1\n",
    "        # update the chosen left and right lane indices (used for plotting) for the current frame\n",
    "        #self.left_lane_inds = left_lane_inds\n",
    "        #self.right_lane_inds = right_lane_inds\n",
    "                        \n",
    "        return leftx, lefty, rightx, righty\n",
    "    \n",
    "    def check_lanes(self):\n",
    "        '''\n",
    "        This function trigger a fresh full scan from next frame onwards if either left or right lane is not getting detected \n",
    "        for more than programmed threshold number of frames\n",
    "        '''\n",
    "        pass\n",
    "        '''\n",
    "        if sum(self.left_lane_inds) <= 50 or sum(self.right_lane_inds) <= 50:\n",
    "            self.numframe_no_l_r += 1\n",
    "            if self.numframe_no_l_r >= self.numframe_thresh:\n",
    "                self.triggerfulscan = 1\n",
    "                print(\"Setting full scan variable to 1...\")\n",
    "            else:\n",
    "                self.triggerfulscan = 0\n",
    "        '''\n",
    "                    \n",
    "        \n",
    "    def plot_lanes(self, img, binary_warped, leftx, lefty, rightx, righty, Minv):\n",
    "        '''\n",
    "        img: un-warped original color image\n",
    "        binary_warped : warped binary thresholded image\n",
    "        nonzeroy : y indices for all non-zero pixels in binary thresholded warped image\n",
    "        nonzerox : x indices for all non-zero pixels in binary thresholded warped image\n",
    "        '''\n",
    "        \n",
    "        if self.triggerfulscan == 1:\n",
    "            return self.prev_result\n",
    "        \n",
    "        ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "        left_fit = np.mean(self.left_fit, axis=0)\n",
    "        right_fit = np.mean(self.right_fit, axis=0)\n",
    "        #print(left_fit)    \n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "                \n",
    "        # Create an image to draw on and an image to show the selection window\n",
    "        out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "        #window_img = np.zeros_like(out_img)\n",
    "        \n",
    "        #left_lane_inds  = self.left_lane_inds\n",
    "        #right_lane_inds = self.right_lane_inds\n",
    "        margin          = self.margin\n",
    "        \n",
    "        # Color in left and right line pixels\n",
    "        out_img[lefty, leftx] = [255, 0, 0]\n",
    "        out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "        # Generate a polygon to illustrate the search window area\n",
    "        # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "        left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "        right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(out_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "        cv2.fillPoly(out_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "                \n",
    "        # un-warp into original image space\n",
    "        unwarp_newimg = cv2.warpPerspective(out_img, Minv, (img.shape[1], img.shape[0]))\n",
    "        result = cv2.addWeighted(img, 1, unwarp_newimg, 0.3, 0)\n",
    "        \n",
    "        # compute ROC on current frame\n",
    "        self.computeROC(binary_warped.shape[0], binary_warped.shape[1])\n",
    "        \n",
    "        # Write the radius of curvature for each lane \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        left_roc = \"Roc: {0:.2f}m\".format(self.left_curverad) \n",
    "        cv2.putText(result, left_roc, (10,650), font, 1, (255,255,255), 2)\n",
    "        right_roc = \"Roc: {0:.2f}m\".format(self.right_curverad) \n",
    "        cv2.putText(result, right_roc, (1020,650), font, 1, (255,255,255), 2)\n",
    "        dist_text = \"Dist from Center: {0:.2f} cms\".format(self.dist_frm_center)\n",
    "        cv2.putText(result, dist_text, (450,50), font, 1, (255,255,255), 2)\n",
    "                \n",
    "        self.prev_result = result\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def computeROC(self, height, width):\n",
    "        '''\n",
    "        This function is to be called from locate_lines\n",
    "        lefty  : y pixels chosen for line fit for left line in current frame\n",
    "        righty : y pixels chosen for line fit for right line in current frame\n",
    "        leftx  : x pixels chosen for line fit for left line in current frame\n",
    "        rightx : x pixels chosen for line fit for right line in current frame\n",
    "        height : height of the image\n",
    "        '''\n",
    "        ploty = np.linspace(0, 719, num=height)# to cover same y-range as image\n",
    "        left_fit = np.mean(self.left_fit, axis=0)\n",
    "        right_fit = np.mean(self.right_fit, axis=0)\n",
    "        # find predictions for left and right x values\n",
    "        leftx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2] \n",
    "        rightx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        \n",
    "        # Define conversions in x and y from pixels space to meters\n",
    "        ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "        xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "        \n",
    "        # Fit new polynomials to x,y in world space\n",
    "        left_fit_cr = np.polyfit(ploty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "        right_fit_cr = np.polyfit(ploty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "        \n",
    "        y_eval = np.max(ploty)\n",
    "        # Calculate the new radii of curvature\n",
    "        left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "        #print(\"max yeval for right:{}\".format(y_eval))\n",
    "        right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "        # Now our radius of curvature is in meters\n",
    "        #print(left_curverad, 'm', right_curverad, 'm')\n",
    "        self.left_curverad = left_curverad\n",
    "        self.right_curverad = right_curverad\n",
    "        # calculate distance from center in real world co-ordinates\n",
    "        img_center = int(width/2)*xm_per_pix\n",
    "        leftcord   = left_fit_cr[0]*(y_eval*ym_per_pix)**2 + left_fit_cr[1]*y_eval*ym_per_pix + left_fit_cr[2]\n",
    "        rightcord  = right_fit_cr[0]*(y_eval*ym_per_pix)**2 + right_fit_cr[1]*y_eval*ym_per_pix + right_fit_cr[2]\n",
    "        self.dist_frm_center = img_center - (rightcord + leftcord)/2\n",
    "               \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# test the lanes detection\n",
    "path = './test_images/*.jpg'\n",
    "images = glob.glob(path)\n",
    "im = cv2.imread(images[0])\n",
    "# undistort the image\n",
    "img_undistort = camera.undistort_image(im)\n",
    "# get the binary image\n",
    "img_binary = camera.threshold_image(img_undistort)\n",
    "# perform perspective transform\n",
    "img_persp = camera.perspective_transform(img_binary)\n",
    "\n",
    "# instantiate object of class Lanes\n",
    "lanes = Lanes()\n",
    "lanes.locate_lines(img_persp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## test scripts\n",
    "test_images = True\n",
    "test_video1 = False\n",
    "test_video2 = False\n",
    "test_video3 = False\n",
    "dump_frames = True\n",
    "def process_image(img):\n",
    "    # undistort the image\n",
    "    img_undistort = camera.undistort_image(img)\n",
    "    # get the binary image\n",
    "    img_binary = camera.threshold_image(img_undistort)\n",
    "    # perform perspective transform\n",
    "    img_persp = camera.perspective_transform(img_binary)\n",
    "    # locate lanes\n",
    "    leftx, lefty, rightx, righty = lanes.locate_lines(img_persp)\n",
    "    # plot the lanes\n",
    "    Minv = camera.Minv\n",
    "    img_with_lanes = lanes.plot_lanes(img,img_persp,leftx,lefty,rightx,righty,Minv)\n",
    "    # check lanes\n",
    "    #lanes.check_lanes()\n",
    "    \n",
    "    \n",
    "    if dump_frames:\n",
    "        fname1 = './video_frames/'+ \"frameno_\"+ str(lanes.frame_no)+ 'undist'+ '.jpg'\n",
    "        fname2 = './video_frames/'+ \"frameno_\"+ str(lanes.frame_no)+ 'binary'+ '.jpg'\n",
    "        fname3 = './video_frames/'+ \"frameno_\"+ str(lanes.frame_no)+ 'persp'+ '.jpg'\n",
    "        fname4 = './video_frames/'+ \"frameno_\"+ str(lanes.frame_no)+ 'withlanes'+ '.jpg'\n",
    "        cv2.imwrite(fname1, img_undistort)\n",
    "        mpimg.imsave(fname2, img_binary)\n",
    "        mpimg.imsave(fname3, img_persp)\n",
    "        cv2.imwrite(fname4, img_with_lanes)\n",
    "        \n",
    "    return img_with_lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if test_images:\n",
    "    save_images = True # all images will be saved\n",
    "    path = './test_images/*.jpg'\n",
    "    writepath = './output_images/'\n",
    "    images = glob.glob(path)\n",
    "    #images = images[0] # for debug\n",
    "    \n",
    "    # create camera class object\n",
    "    camera = Camera(num_xpts=6, num_ypts=9)\n",
    "    # create lanes class object\n",
    "    lanes  = Lanes()\n",
    "    # Reload the camera matrix and distortion coeff\n",
    "    pickle_file = 'camera_calib.pickle'\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "      pickle_data = pickle.load(f)\n",
    "      mtx = pickle_data['camera_mat']\n",
    "      dist = pickle_data['dist_coeff']\n",
    "      del pickle_data  # Free up memory\n",
    "\n",
    "    print('Data and modules loaded.')\n",
    "    # set the camera matrix and distortion coeff\n",
    "    camera.set_camera_calib(mtx,dist)\n",
    "    \n",
    "    # Setup the plot grid for test images\n",
    "    plt.figure(figsize = (20,20))\n",
    "    gs1 = gridspec.GridSpec(len(images),2)\n",
    "    gs1.update(wspace=0.025, hspace=0.025)\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    for img in images:\n",
    "        test_image = cv2.imread(img)\n",
    "        img_withdetection = process_image(test_image)\n",
    "        if save_images is True:\n",
    "            # save the image\n",
    "            y=img.split('\\\\')\n",
    "            fname = writepath + y[1] \n",
    "            cv2.imwrite(fname,img_withdetection)\n",
    "            \n",
    "        b,g,r = cv2.split(img_withdetection)\n",
    "        img_withdetection = cv2.merge((r,g,b))\n",
    "        ax1 = plt.subplot(gs1[i])\n",
    "        plt.axis('off')\n",
    "        b,g,r = cv2.split(test_image)\n",
    "        test_image = cv2.merge((r,g,b))\n",
    "        ax1.imshow(test_image)\n",
    "        ax2 = plt.subplot(gs1[i+1])\n",
    "        plt.axis('off')\n",
    "        ax2.imshow(img_withdetection)\n",
    "        i+=2\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_images = False\n",
    "test_video1 = True\n",
    "test_video2 = False\n",
    "test_video3 = False\n",
    "dump_frames = False\n",
    "if test_video1:\n",
    "    print(\"Running on test video1...\")\n",
    "    writepath = './output_images/'\n",
    "    \n",
    "    # create camera class object\n",
    "    camera = Camera(num_xpts=6, num_ypts=9)\n",
    "    # create lanes class object\n",
    "    lanes  = Lanes()\n",
    "    # Reload the camera matrix and distortion coeff\n",
    "    pickle_file = 'camera_calib.pickle'\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "      pickle_data = pickle.load(f)\n",
    "      mtx = pickle_data['camera_mat']\n",
    "      dist = pickle_data['dist_coeff']\n",
    "      del pickle_data  # Free up memory\n",
    "\n",
    "    print('Data and modules loaded.')\n",
    "    # set the camera matrix and distortion coeff\n",
    "    camera.set_camera_calib(mtx,dist)\n",
    "    \n",
    "    #####################################\n",
    "    # Run our pipeline on the test video \n",
    "    #####################################\n",
    "    clip = VideoFileClip(\"./project_video.mp4\")\n",
    "    output_video = \"./project_video_processed_111.mp4\"\n",
    "    output_clip = clip.fl_image(process_image)\n",
    "    output_clip.write_videofile(output_video, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on test video2...\n",
      "Data and modules loaded.\n",
      "[MoviePy] >>>> Building video ./project_video_processed_222.mp4\n",
      "[MoviePy] Writing video ./project_video_processed_222.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▋                                   | 68/485 [00:09<01:05,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████▊                                  | 81/485 [00:10<00:54,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████▍                                 | 88/485 [00:11<01:00,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▏                                | 97/485 [00:13<00:57,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▉                               | 109/485 [00:15<00:57,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████▏                              | 112/485 [00:15<01:13,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████▍                              | 115/485 [00:16<01:16,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████▉                             | 132/485 [00:24<01:05,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████▋                 | 275/485 [00:43<00:26,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████▉    | 435/485 [01:06<00:06,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 485/485 [01:13<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./project_video_processed_222.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_images = False\n",
    "test_video1 = False\n",
    "test_video2 = True\n",
    "test_video3 = False\n",
    "dump_frames = False\n",
    "if test_video2:\n",
    "    print(\"Running on test video2...\")\n",
    "    writepath = './output_images/'\n",
    "    \n",
    "    # create camera class object\n",
    "    camera = Camera(num_xpts=6, num_ypts=9)\n",
    "    # create lanes class object\n",
    "    lanes  = Lanes()\n",
    "    # Reload the camera matrix and distortion coeff\n",
    "    pickle_file = 'camera_calib.pickle'\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "      pickle_data = pickle.load(f)\n",
    "      mtx = pickle_data['camera_mat']\n",
    "      dist = pickle_data['dist_coeff']\n",
    "      del pickle_data  # Free up memory\n",
    "\n",
    "    print('Data and modules loaded.')\n",
    "    # set the camera matrix and distortion coeff\n",
    "    camera.set_camera_calib(mtx,dist)\n",
    "    \n",
    "    #####################################\n",
    "    # Run our pipeline on the test video \n",
    "    #####################################\n",
    "    clip = VideoFileClip(\"./challenge_video.mp4\")\n",
    "    output_video = \"./project_video_processed_222.mp4\"\n",
    "    output_clip = clip.fl_image(process_image)\n",
    "    output_clip.write_videofile(output_video, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on test video3...\n",
      "Data and modules loaded.\n",
      "[MoviePy] >>>> Building video ./project_video_processed_333.mp4\n",
      "[MoviePy] Writing video ./project_video_processed_333.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████▍                      | 505/1200 [01:24<01:34,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████▌                      | 508/1200 [01:24<01:37,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████▎        | 934/1200 [02:29<00:39,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████        | 955/1200 [02:33<00:34,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████▊      | 1004/1200 [02:40<00:25,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fullscan triggered....\n",
      "Frameno:1005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████▉| 1199/1200 [03:09<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./project_video_processed_333.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_images = False\n",
    "test_video1 = False\n",
    "test_video2 = False\n",
    "test_video3 = True\n",
    "dump_frames = False\n",
    "if test_video3:\n",
    "    print(\"Running on test video3...\")\n",
    "    writepath = './output_images/'\n",
    "    \n",
    "    # create camera class object\n",
    "    camera = Camera(num_xpts=6, num_ypts=9)\n",
    "    # create lanes class object\n",
    "    lanes  = Lanes()\n",
    "    # Reload the camera matrix and distortion coeff\n",
    "    pickle_file = 'camera_calib.pickle'\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "      pickle_data = pickle.load(f)\n",
    "      mtx = pickle_data['camera_mat']\n",
    "      dist = pickle_data['dist_coeff']\n",
    "      del pickle_data  # Free up memory\n",
    "\n",
    "    print('Data and modules loaded.')\n",
    "    # set the camera matrix and distortion coeff\n",
    "    camera.set_camera_calib(mtx,dist)\n",
    "    \n",
    "    #####################################\n",
    "    # Run our pipeline on the test video \n",
    "    #####################################\n",
    "    clip = VideoFileClip(\"./harder_challenge_video.mp4\")\n",
    "    output_video = \"./project_video_processed_333.mp4\"\n",
    "    output_clip = clip.fl_image(process_image)\n",
    "    output_clip.write_videofile(output_video, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
